{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading checkpoint: Meso2V1_1.13.pth\n",
      "Checkpoint loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Ensure CUDA is available\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Ensure you have a compatible PyTorch version installed!\")\n",
    "\n",
    "# Force PyTorch to use GPU\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class Meso4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Meso4, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 8, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(8, 8, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(8, 16, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(16, 16, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class DeepFakeVideoDataset(Dataset):\n",
    "    def __init__(self, real_videos, fake_videos, transform=None, num_frames=5):\n",
    "        self.real_videos = real_videos\n",
    "        self.fake_videos = fake_videos\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        self.data = [(vid, 0) for vid in self.real_videos] + [(vid, 1) for vid in self.fake_videos]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.data[idx]\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        frames = []\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        selected_indices = np.linspace(0, frame_count - 1, self.num_frames, dtype=int)\n",
    "\n",
    "        for i in range(frame_count):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if i in selected_indices:\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image = Image.fromarray(image)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                frames.append(image)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) == 0:\n",
    "            print(f\"Skipping video {video_path} due to no valid frames.\")\n",
    "            return self.__getitem__(np.random.randint(0, len(self)))\n",
    "\n",
    "        return torch.stack(frames).to(device), torch.tensor(label, dtype=torch.long, device=device)\n",
    "\n",
    "def resume_training(model, train_loader, epochs=10, lr=0.001, checkpoint_path=\"Meso2V1_1.13.pth\"):\n",
    "    model.to(device)  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        print(\"Checkpoint loaded successfully!\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct_train, total_train = 0, 0, 0\n",
    "\n",
    "        for frames, labels in train_loader:\n",
    "            frames, labels = frames.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            frames = frames[:, 0, :, :, :]  \n",
    "\n",
    "            outputs = model(frames)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}, Acc: {train_acc:.2f}%\")\n",
    "\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "# Dataset Paths\n",
    "real_videos_dir = \"E:\\\\dataset\\\\Dataset Videos\\\\DFD_original sequences\"\n",
    "fake_videos_dir = \"E:\\\\dataset\\\\Dataset Videos\\\\DFD_manipulated_sequences\\\\DFD_manipulated_sequences\"\n",
    "\n",
    "real_videos = [os.path.join(real_videos_dir, f) for f in os.listdir(real_videos_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "fake_videos = [os.path.join(fake_videos_dir, f) for f in os.listdir(fake_videos_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "dataset = DeepFakeVideoDataset(real_videos, fake_videos, transform=transform, num_frames=5)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = Meso4().to(device)\n",
    "resume_training(model, train_loader, epochs=10, lr=0.001, checkpoint_path=\"Meso2V1_1.13.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
